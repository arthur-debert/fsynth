TECHNICAL BRIEFING: SYNTHETIC FILESYSTEM (FSYNTH) IMPLEMENTATION
===============================================================

Overview
--------
This briefing outlines the implementation strategy for a synthetic filesystem
(fsynth) component that isolates filesystem operations into an operation queue
to be executed in batches. This approach separates planning from execution,
enabling reliable testing, dry-run capabilities, and controlled error handling.

Background and Rationale
-----------------------
Filesystem operations pose several challenges in application development:
1. They create side effects, making testing difficult
2. Errors during operations can leave the system in an inconsistent state
3. Operations are often interdependent (e.g., creating a directory before
   creating a file within it)

The synthetic filesystem pattern addresses these challenges by:
- Planning all operations without executing them
- Accumulating operations in a queue
- Validating operations before execution
- Executing operations in a controlled manner
- Providing rollback capabilities where possible

This pattern aligns with the functional approach described in our design 
principles, where we maintain most of the codebase as pure functions and
isolate side effects to a small part of the code.

Core Requirements
----------------
The fsynth implementation must:

1. Queue filesystem operations without executing them
2. Support file checksumming to verify file integrity
3. Implement directory traversal with safety limits
4. Provide flexible execution strategies
5. Offer error handling with optional rollback
6. Maintain detailed operation logging

Component Design
---------------
The synthetic filesystem consists of four main components:

1. OPERATIONS
   Individual filesystem actions like copy, create, symlink, or delete.
   Each operation encapsulates all necessary data and behavior [1].

2. QUEUE
   An efficient data structure for storing operations in the order they
   should be executed [2].

3. PROCESSOR
   A component responsible for executing the operations in the queue,
   handling errors, and managing rollback if needed [3].

4. EXECUTION CONTEXT
   Shared state and configuration for operation execution.

Operation Types
--------------
The implementation will support these core operations:

1. CREATE_FILE
   - Creates a new file with specified content
   - Optionally creates parent directories
   - Records checksum of created file

2. COPY_FILE
   - Copies a file from source to destination
   - Checksums both source and destination
   - Optionally backs down if source has changed

3. SYMLINK
   - Creates a symbolic link from source to target
   - Handles existing target files/links
   - Works with relative or absolute paths

4. CREATE_DIRECTORY
   - Creates a directory and any required parent directories
   - Handles permissions
   - Can be exclusive (fail if exists) or inclusive

5. MOVE
   - Moves a file or directory
   - Records checksums for files

6. DELETE
   - Removes a file or directory
   - Implements safety checks (max files for directories)
   - Optionally creates backups before deletion

7. CHMOD
   - Changes file permissions
   - Records the original permissions for possible rollback

Checksumming Functionality
-------------------------
File checksums are a critical part of maintaining integrity:

1. Each file operation records checksums where appropriate
2. Source checksums verify files haven't changed since queue creation
3. Target checksums allow detecting conflicts before overwriting
4. Options control behavior when checksums don't match:
   - Fail operation
   - Force overwrite
   - Skip operation
   - Create backup

Directory Processing Safety
--------------------------
To prevent excessive processing of large directories:

1. Directory operations include a configurable item limit (default ~1000)
2. An accumulator tracks items processed during directory traversal
3. Clear warnings/errors are raised when limits are reached
4. Options determine behavior at limit:
   - Stop processing
   - Continue with warning
   - Skip subdirectories
   - Process specific patterns only

The directory accumulator serves as a safeguard against pointing the system
at enormous directory trees. This is especially important for recursive
operations.

Queue Management
---------------
Operations will be stored in an efficient queue implementation:

1. Use a two-pointer queue structure with O(1) enqueue/dequeue [2]
2. Operations remain immutable once queued
3. Processor controls queue execution
4. Support operation prioritization (directory creation before file creation)

Execution Strategies
-------------------
The processor supports multiple execution models:

1. SEQUENTIAL
   Execute operations in order, stopping on first error

2. VALIDATE_FIRST
   Validate all operations before executing any

3. BEST_EFFORT
   Try all operations, collecting errors but continuing

4. TRANSACTIONAL
   Attempt rollback of completed operations on failure

Each strategy serves different use cases, from strict correctness to
maximum attempt at completion.

Error Handling
-------------
Error handling is comprehensive:

1. Each operation has standardized error reporting
2. Errors are classified (fatal vs non-fatal)
3. Context-rich error messages include:
   - Operation type and parameters
   - Filesystem state information
   - Error phase (validation, execution, rollback)
   - Underlying system error
4. Error collection allows analysis of failed batches

Testing Approach
--------------
The synthetic filesystem design enables thorough testing:

1. UNIT TESTING
   - Test each operation type in isolation
   - Verify proper checksum handling
   - Test various error conditions

2. INTEGRATION TESTING
   - Test full operation sequences
   - Verify correct execution order
   - Test rollback capabilities
   - Verify checksumming behavior

Technology Stack
--------------
Implementation will use:

1. Penlight for path handling and basic filesystem operations
2. Busted for testing
3. SHA-256 for checksumming
4. Standard Lua tables with metatables for operation objects

Implementation Priorities
-----------------------
Suggested implementation order:

1. Core operation interfaces
2. Basic file operations
3. Queue management
4. Directory handling with safety limits
5. Checksumming implementation
6. Processor with execution strategies
7. Error handling and rollback
8. Testing infrastructure

Integration
----------
The synthetic filesystem will integrate with the existing codebase as follows:

1. Handlers will build operation queues instead of modifying the filesystem
2. A dedicated processor will execute these queues
3. Options will control execution behavior
4. Dry-run mode will validate but not execute operations

Code examples for each core component are provided separately in
fsynth.txxt. See numbered references [1], [2], and [3] for detailed
implementation examples.

References
---------
[1] Operation Interface - See fsynth.txxt for implementation
[2] Queue Management - See fsynth.txxt for implementation  
[3] Processor Implementation - See fsynth.txxt for implementation